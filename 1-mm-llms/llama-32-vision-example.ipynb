{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19e691f1-e5d5-4aa4-a53e-6ddcdd23e18d",
   "metadata": {},
   "source": [
    "# Exploring Llama 3.2-Vision (locally) with Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "353a71c8-f7c8-4e7d-93df-d3a55cd6b039",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6d3101c-e898-4bcb-a871-22c8f6568dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77b99af-7ca5-4628-9377-ddd0f5bf30c7",
   "metadata": {},
   "source": [
    "### pull model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "726a200d-921e-4a8e-a38b-4ac38a99ad25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProgressResponse(status='success', completed=None, total=None, digest=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ollama.pull('llama3.2-vision')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c77b5ab-7cd6-4815-b12c-6f7c58dbb5aa",
   "metadata": {},
   "source": [
    "#### Basic Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28b2b58b-3482-4214-9f03-b57b2438ad3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image shows a woman taking a photo of herself with her smartphone while sitting at a small table at an outdoor cafe. She is wearing a red jacket, a white hat, and has long blonde hair. The table has a coffee cup and a book on it.\n"
     ]
    }
   ],
   "source": [
    "response = ollama.chat(\n",
    "    model='llama3.2-vision',\n",
    "    messages=[{\n",
    "        'role': 'user',\n",
    "        'content': 'What is in this image?',\n",
    "        'images': ['images/selfie.jpg']\n",
    "    }]\n",
    ")\n",
    "\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfabe75-b6e2-41f4-8538-371192135ae2",
   "metadata": {},
   "source": [
    "#### Image captioning - streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc29b737-6f86-4cee-a7c4-274ba2f10c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A woman in a red coat and white hat sits at a small round table in a street-side cafe, taking a selfie with her phone."
     ]
    }
   ],
   "source": [
    "stream = ollama.chat(\n",
    "    model='llama3.2-vision',\n",
    "    messages=[{\n",
    "        'role': 'user',\n",
    "        'content': 'Can you write a caption for this image?',\n",
    "        'images': ['images/selfie.jpg']\n",
    "    }],\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "for chunk in stream:\n",
    "    print(chunk['message']['content'], end='', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053d3738-a3c0-4d44-83b8-7f90ddce9cd6",
   "metadata": {},
   "source": [
    "#### Explaining memes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1ac5d88-6438-4ff6-849b-a888c90d8790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This meme pokes fun at how many AI tools and services are available today. It shows a character from SpongeBob, Patrick, trying to build a bench but is surrounded by many different AI tools and services. The meme is meant to be humorous and relatable, as it pokes fun at how many options are available for building with AI today. The meme is meant to be humorous and relatable, as it pokes fun at how many options are available for building with AI today."
     ]
    }
   ],
   "source": [
    "stream = ollama.chat(\n",
    "    model='llama3.2-vision',\n",
    "    messages=[{\n",
    "        'role': 'user',\n",
    "        'content': 'Can you explain this meme to me?',\n",
    "        'images': ['images/ai-meme.jpeg']\n",
    "    }],\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "for chunk in stream:\n",
    "    print(chunk['message']['content'], end='', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73926c2f-826f-4a15-8a67-b5ca4e4b6d9e",
   "metadata": {},
   "source": [
    "#### OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06e911d1-533d-48ba-923a-549544aba5b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the text from the screenshot in a markdown format:\n",
      "\n",
      "# 5 AI Projects You Can Build This Weekend (with Python)\n",
      "\n",
      "### 1. **Resume Optimization (Beginner)**\n",
      "\n",
      "* Idea: build a tool that adapts your resume for a specific job description\n",
      "\n",
      "### 2. **YouTube Lecture Summarizer (Beginner)**\n",
      "\n",
      "* Idea: build a tool that takes a YouTube video link and summarizes it\n",
      "\n",
      "### 3. **Auto-Organize PDFs (Intermediate)**\n",
      "\n",
      "* Idea: build a tool to analyze the contents of each PDF and organize them into folders based on topics\n",
      "\n",
      "### 4. **Multimodal Search (Intermendh)\n",
      "\n",
      "* Idea: use multimodality to represent user queries, text knowledge, and images in single space\n",
      "\n",
      "### 5. **Desktop QA (Advanced)\n",
      "\n",
      "* Idea: connect a multmodl\n",
      " base to a model like Llama-3.2-11B-VI\n",
      "ision."
     ]
    }
   ],
   "source": [
    "stream = ollama.chat(\n",
    "    model='llama3.2-vision',\n",
    "    messages=[{\n",
    "        'role': 'user',\n",
    "        'content': 'Can you transcribe the text from this screenshot in a markdown format?',\n",
    "        'images': ['images/5-ai-projects.jpeg']\n",
    "    }],\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "for chunk in stream:\n",
    "    print(chunk['message']['content'], end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a00c43-bd5f-4a5a-8f73-03b8deabed82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
